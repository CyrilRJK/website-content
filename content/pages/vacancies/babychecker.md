title: Improving prenatal screening in  developing countries with AI-powered handheld ultrasound
groups: diag
closed: false
type: general 
picture: vacancies/babychecker.jpg
people: Bram van  Ginneken, Chris de Korte
template: vacancy-single
description: We are offering a PhD position to develop real-time AI analysis of handheld ultrasound to bring affordable prenatal screening to developing countries.


## Background and job description
Every day more than 800 women die as a consequence of their pregnancy, of which 91% occur in low and middle-income countries. Ultrasound imaging can be used to detect maternal risk factors and is recommended wy the World Health Organization, but is barely used in these countries. This is caused by the lack of trained sonographers that can perform prenatal scanning and the high cost of ultrasound equipment. The latter obstacle is alleviated by handheld ultrasound devices that are now becoming available on the market for relatively low prices. Most of these can be connected to a phone or tablet. To obviate the need of a trained sonographer, we propose to combined a standardize acquisition protocol (consisting of several sweeps over the belly of the pregnant woman) with real-time feedback by deep learning algorithms followed by automated interpretation with deep learning. In the past, algorithms were developed in our group for automated to detect twin pregnancies, estimate gestational age, determine fetal presentation and determine placenta location. All developed algorithms were ported to an Android based app called the BabyChecker and data collection and field tests with this research prototype have started in several African countries by our industry partner Delft Imaging.

You should be a highly motivated, creative, and enthusiastic researcher with an MSc degree in Computer Science, Data Science, Physics, Mathematics, Engineering, or related. You have a good understanding of deep learning and have the skills to adapt deep learning algorithms. Good knowledge of medical imaging, ultrasound in particular, is a plus. The research should result in a Ph.D. thesis, requiring you to have good communication skills to excel at presenting results at scientific meetings and in scientific journals.

## Organization
DIAG is an internationally renowned group on deep learning for medical imaging. The DIAG PhDs will research deep learning models for reconstruction and steering in diagnosis and intervention. You will work in a large group of skilled deep learning researchers in an agile, clinically targetted approach. 

The PhDs will work at DIAG (diagnijmegen.nl) in strong collaboration with the other scientific and industrial partners in the FastMRI project. DIAG currently has 50 deep learning researchers focused on various medical image analysis topics. The focus of DIAG is the development and validation of novel methods in a broad range of medical imaging applications. Application areas include neuro, breast, prostate, lung, pancreas and retina imaging and digital pathology. The key to the success of DIAG is close cooperation with clinicians. A team of scientific programmers supports deep learning research, maintaining a large cluster of computers equipped with high-end GPUs for large-scale experimentation. The Diagnostic Image Analysis Group (DIAG) is a research division of the Departments of Radiology and Nuclear Medicine/Pathology of the Radboud University Medical Center Nijmegen. Nijmegen is the oldest Dutch city with a rich history and one of the liveliest city centers in the Netherlands. Radboud University has over 17,000 students. Radboud UMC is a leading academic center for medical science, education, and healthcare with over 8,500 staff and 3,000 students. 

## Applications
A link to apply online will be posted here shortly. Until the link is available, you can apply directly by  sending an e-mail to Bram van Ginneken. Your application must include a motivation letter that clearly explains your match to all aspects of the requested profile. Your letter is supplemented by a complete CV, summary grades, and links to your code and your publications. Questions can be directed to Bram van Ginneken or Chris de Korte.


## Information
For more information please contact [member/bram-van-ginneken] by e-mail.

